{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h__tW2y9j3HA"
      },
      "source": [
        "##### Summary of the Paper - https://doi.org/10.1371/journal.pone.0308045\n",
        "The paper proposes a method to improve human activity classification using micro-Doppler (m-D) signatures from FMCW radar. Key contributions include:\n",
        "\n",
        "Denoising Algorithm: It is a two step algorithm -\n",
        "\n",
        "* Step 1: Determine the optimal range-bin interval using minimum entropy to focus on relevant signal regions.\n",
        "\n",
        "* Step 2: Apply a cut-threshold to remove noise from the STFT of selected range-bins.\n",
        "\n",
        "Cross-Residual CNN (CRCNN): A lightweight CNN with cross-residual connections and multi-scale filters to enhance feature extraction from denoised spectrograms.\n",
        "\n",
        "The model achieves 99% accuracy at -10 dB SNR after denoising."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_7NTM-Uj3HB"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import scipy.io\n",
        "from scipy.signal import stft\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpVkN6ukj3HC",
        "outputId": "2ade52aa-99ae-41c6-a6b2-ad5e99245b51"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n",
        "# os.chdir('/content/drive/MyDrive/Huy/ECE613_new')\n",
        "# file_path = os.getcwd() + '/W/W/3m_0_file60.mat'\n",
        "\n",
        "\n",
        "def load_radar_data(file_path):\n",
        "    \"\"\"Load radar data from .mat file.\"\"\"\n",
        "    data = scipy.io.loadmat(file_path)\n",
        "    signal_data = data['received_time_domain_signal']  # Shape: (num_chirps, num_samples)\n",
        "    return signal_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a-_NMqxawIQ"
      },
      "source": [
        "## Load Data Here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro4ci0lUaw2J"
      },
      "outputs": [],
      "source": [
        "#TODO: Make this for loop for running multiple files for benchmarking\n",
        "file_path = os.getcwd() + '/clean_data/W/3m_0_file30.mat'\n",
        "data_matrix = load_radar_data(file_path)\n",
        "snr_list = [-15, -5, 0, 5, 10]\n",
        "fs_slow = 1000.0\n",
        "# optimal_range_bin = (7,10)\n",
        "r_values=[1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqxWdqC2byw0"
      },
      "source": [
        "## Utils Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iLq0MmlYCE-"
      },
      "outputs": [],
      "source": [
        "def plot_original_spectrogram(f, t, spec_db, title=\"Original Micro-Doppler Spectrogram\",\n",
        "                              freq_lims=None, time_lims=None, caxis=None):\n",
        "    plt.figure(figsize=(8,6))\n",
        "    extent = [t.min(), t.max(), f[0], f[-1]]\n",
        "    plt.imshow(spec_db, origin='lower', aspect='auto', extent=extent, cmap='jet')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Doppler Frequency (Hz)\")\n",
        "    cbar = plt.colorbar(label=\"Magnitude (dB)\")\n",
        "\n",
        "    if caxis is not None:\n",
        "        plt.clim(caxis[0], caxis[1])\n",
        "    if freq_lims:\n",
        "        plt.ylim(freq_lims)\n",
        "    if time_lims:\n",
        "        plt.xlim(time_lims)\n",
        "    plt.tight_layout()\n",
        "    # plt.savefig('spectrogram_W_org_30.png')\n",
        "    plt.show()\n",
        "\n",
        "def add_awgn(data, snr_db):\n",
        "    \"\"\"\n",
        "    Add white Gaussian noise to 'data' to achieve the desired SNR in dB.\n",
        "    data: numpy array (can be real or complex).\n",
        "    snr_db: desired SNR in dB (float).\n",
        "    Returns: noisy_data (same shape as data).\n",
        "    \"\"\"\n",
        "    # 1) Compute signal power\n",
        "    sig_power = np.mean(np.abs(data)**2)\n",
        "    # 2) Compute noise variance for desired SNR\n",
        "    snr_linear = 10**(snr_db/10.0)\n",
        "    noise_var = sig_power / snr_linear\n",
        "\n",
        "    # 3) Generate noise\n",
        "    if np.iscomplexobj(data):\n",
        "        # Complex data => complex noise\n",
        "        noise = (np.sqrt(noise_var/2.0) *\n",
        "                 (np.random.randn(*data.shape) + 1j*np.random.randn(*data.shape)))\n",
        "    else:\n",
        "        # Real data => real noise\n",
        "        noise = np.sqrt(noise_var)*np.random.randn(*data.shape)\n",
        "\n",
        "    # 4) Add noise\n",
        "    noisy_data = data + noise\n",
        "    return noisy_data\n",
        "\n",
        "# Example function to do everything: generate & plot multiple noisy spectrograms\n",
        "def generate_noisy_spectrograms(data_matrix, snr_values, fs_slow=1000.0):\n",
        "    \"\"\"\n",
        "    data_matrix: your original data (num_chirps x num_samples)\n",
        "    snr_values: list of SNRs in dB, e.g. [-15, -5, 0, 5, 10]\n",
        "    fs_slow: slow-time sampling frequency\n",
        "    \"\"\"\n",
        "    for snr_db in snr_values:\n",
        "        # Create a noisy copy\n",
        "        data_noisy = add_awgn(data_matrix, snr_db)\n",
        "\n",
        "        # Then pass 'data_noisy' to your spectrogram function (like test_compute_spectrogram_2)\n",
        "        f_centered, t, spec_db_centered = compute_spectrogram(data_noisy, r_values=[1], fs_slow=fs_slow)\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(8,6))\n",
        "        extent = [t.min(), t.max(), f_centered[0], f_centered[-1]]\n",
        "        plt.imshow(spec_db_centered, origin='lower', aspect='auto', extent=extent, cmap='jet')\n",
        "        plt.title(f\"Centered Micro-Doppler Spectrogram (SNR={snr_db} dB)\")\n",
        "        plt.xlabel(\"Time (s)\")\n",
        "        plt.ylabel(\"Doppler Frequency (Hz)\")\n",
        "        cbar = plt.colorbar(label=\"Magnitude (dB)\")\n",
        "        plt.clim(-60, -20)  # or adjust\n",
        "        # plt.ylim([-400, 400]) # if you want to zoom\n",
        "        plt.xlim([0, 8])      # if you have 8 s\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vYxW3BYj3HE"
      },
      "source": [
        "### Optimal Range-Bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-Y2CjLwj3HF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import stft\n",
        "\n",
        "# **Function 1: Compute and visualize the full FFT processing**\n",
        "def compute_full_fft(signal_data):\n",
        "    \"\"\"\n",
        "    Compute and visualize the full FFT processing (Range FFT + Doppler FFT).\n",
        "\n",
        "    Parameters:\n",
        "    - signal_data: numpy array of shape (num_chirps, num_samples)\n",
        "    \"\"\"\n",
        "    num_chirps, num_samples = signal_data.shape\n",
        "\n",
        "    # Compute Range FFT (Fast-Time FFT)\n",
        "    range_fft = np.fft.fft(signal_data, axis=1)  # FFT along samples\n",
        "    range_fft_magnitude = np.abs(range_fft)  # Get magnitude\n",
        "\n",
        "    # Plot Range FFT\n",
        "    # plt.figure(figsize=(10, 5))\n",
        "    # plt.imshow(20 * np.log10(range_fft_magnitude), aspect='auto', cmap='jet')\n",
        "    # plt.title(\"Range FFT (Fast Time)\")\n",
        "    # plt.xlabel(\"Samples (Range Bins)\")\n",
        "    # plt.ylabel(\"Chirps\")\n",
        "    # plt.colorbar(label=\"Magnitude (dB)\")\n",
        "    # plt.show()\n",
        "\n",
        "    return range_fft_magnitude\n",
        "\n",
        "\n",
        "# **Function 2: Compute STFT of the given signal**\n",
        "def compute_stft(signal_data, fs=1e6, window='hann'):\n",
        "    \"\"\"\n",
        "    Compute the Short-Time Fourier Transform (STFT) of the given signal.\n",
        "\n",
        "    Parameters:\n",
        "        signal_data (ndarray): Input time-domain signal.\n",
        "        fs (float): Sampling frequency.\n",
        "        nperseg (int): Window length for STFT.\n",
        "        window (str): Window function type.\n",
        "        noverlap (int or None): Overlap between segments.\n",
        "\n",
        "    Returns:\n",
        "        f (ndarray): Frequency bins.\n",
        "        t (ndarray): Time bins.\n",
        "        Zxx (ndarray): Complex STFT result.\n",
        "        Zxx_magnitude (ndarray): Magnitude of STFT in dB.\n",
        "    \"\"\"\n",
        "    # if noverlap is None:\n",
        "    #     noverlap = nperseg // 2  # Default 50% overlap\n",
        "\n",
        "    # # Ensure noverlap is strictly less than nperseg\n",
        "    # if noverlap >= nperseg:\n",
        "    #     noverlap = nperseg - 1  # This ensures noverlap is strictly less than nperseg\n",
        "\n",
        "    f, t, Zxx = stft(signal_data, fs=fs, window=window, return_onesided=False)\n",
        "\n",
        "    # Convert magnitude to dB, ensuring numerical stability\n",
        "    Zxx_magnitude = 10 * np.log10(np.abs(Zxx) + np.finfo(float).eps)\n",
        "\n",
        "    return f, t, Zxx, Zxx_magnitude\n",
        "\n",
        "\n",
        "# **Function 3: Compute entropy for the STFT result**\n",
        "def compute_entropy(Zxx, tau_index):\n",
        "    \"\"\"\n",
        "    Compute Shannon entropy of the frequency distribution at a specific time index.\n",
        "\n",
        "    Parameters:\n",
        "        Zxx (ndarray): STFT complex result.\n",
        "        tau_index (int): Index corresponding to time τ.\n",
        "\n",
        "    Returns:\n",
        "        entropy (float): Shannon entropy in bits.\n",
        "    \"\"\"\n",
        "    magnitude_spectrum = np.abs(Zxx[:, tau_index])\n",
        "\n",
        "    # Normalize to obtain probability distribution\n",
        "    P = magnitude_spectrum / np.sum(magnitude_spectrum)\n",
        "    P = P[P > 0]  # Remove zero elements to avoid log(0)\n",
        "\n",
        "    # Compute entropy\n",
        "    entropy = -np.sum(P * np.log2(P))\n",
        "\n",
        "    return entropy\n",
        "\n",
        "# **Function 4: Compute average entropy for the STFT result**\n",
        "def compute_average_entropy(Zxx, t):\n",
        "    \"\"\"\n",
        "    Compute the average entropy across all time bins.\n",
        "\n",
        "    Parameters:\n",
        "        Zxx (ndarray): STFT complex result.\n",
        "        t (ndarray): Time bins.\n",
        "\n",
        "    Returns:\n",
        "        average_entropy (float): Average Shannon entropy over time.\n",
        "    \"\"\"\n",
        "    entropies = []\n",
        "    for tau_index in range(len(t)):\n",
        "        entropy = compute_entropy(Zxx, tau_index)\n",
        "        entropies.append(entropy)\n",
        "\n",
        "    average_entropy = np.mean(entropies)\n",
        "    return average_entropy\n",
        "\n",
        "# **Function 5: Process all chirps, including FFT, STFT, and entropy calculations**\n",
        "def get_optimal_range_bin(data_matrix, r_values):\n",
        "    \"\"\"\n",
        "    Process all chirps in the data matrix: Compute FFT, STFT, entropy, and average entropy.\n",
        "\n",
        "    Parameters:\n",
        "        data_matrix (ndarray): Input data matrix of shape (num_chirps, num_samples).\n",
        "        r_values (list): List of range intervals for defining r_q.\n",
        "    \"\"\"\n",
        "    num_chirps, num_samples = data_matrix.shape\n",
        "    P_max = []\n",
        "\n",
        "    # Compute full FFT for all chirps\n",
        "    range_fft_magnitude = compute_full_fft(data_matrix)\n",
        "\n",
        "    # Step 2a: Find P_max for each chirp\n",
        "    for i in range(num_chirps):\n",
        "        P_max_value = np.max(range_fft_magnitude[i, :])  # Maximum value in the FFT magnitude\n",
        "        P_max.append(P_max_value)\n",
        "\n",
        "    # Step 2b: Find most frequent index in P_max\n",
        "    idx_max = np.argmax(np.bincount(np.array(P_max, dtype=int)))  # Most frequent index\n",
        "\n",
        "    # Step 3: For each q in Q, define range r_q and compute STFT\n",
        "    min_entropy = float('inf')  # Initialize min_entropy\n",
        "    best_r_opt = None  # Initialize best range\n",
        "\n",
        "    for q in range(len(r_values)):\n",
        "        r_q = np.arange(idx_max - r_values[q], idx_max + r_values[q])  # Fix: cast idx_max to int\n",
        "\n",
        "        # Select the range of the signal for the defined r_q\n",
        "        signal_range = data_matrix[:, r_q]\n",
        "\n",
        "        # Compute STFT for this range\n",
        "        for chirp_index in range(num_chirps):\n",
        "            signal_data = signal_range[chirp_index]\n",
        "            f, t, Zxx, Zxx_magnitude = compute_stft(signal_data)\n",
        "\n",
        "            # Step 3b: Calculate average entropy for the range r_q\n",
        "            avg_entropy = compute_average_entropy(Zxx, t)\n",
        "            # print(f\"Average Entropy for range r_q = {r_values[q]}: {avg_entropy:.4f} bits\")\n",
        "\n",
        "            # Update optimal range-bin if entropy is lower\n",
        "            if avg_entropy < min_entropy:\n",
        "                min_entropy = avg_entropy\n",
        "                best_r_opt = r_q\n",
        "\n",
        "    # Compute the optimal range-bin interval (Equation 11)\n",
        "    optimal_range_bin = (idx_max - best_r_opt[0], idx_max + best_r_opt[-1])  # Fix the interval calculation\n",
        "    return optimal_range_bin\n",
        "\n",
        "def compute_spectrogram(data_matrix, r_values, fs_slow=1000.0):\n",
        "    \"\"\"\n",
        "    data_matrix: shape (num_chirps, num_fast_time_samples) if raw,\n",
        "                 or shape (num_chirps, num_range_bins) if already range-FFT.\n",
        "    r_values: list of half-widths around idx_max.\n",
        "    fs_slow: slow-time sampling rate (e.g. 1000 Hz).\n",
        "    \"\"\"\n",
        "    num_chirps, num_samples = data_matrix.shape\n",
        "    P_max = []\n",
        "    # print(\"data_matrix shape:\", data_matrix.shape)\n",
        "\n",
        "    # 1) If data_matrix is raw, do range FFT:\n",
        "    #    But if your data is already range-FFT, skip this.\n",
        "    # Example:\n",
        "    # range_fft_data = np.fft.fft(data_matrix, axis=1)\n",
        "    # range_fft_mag = np.abs(range_fft_data)\n",
        "    # For demonstration, let's assume data_matrix is ALREADY range-FFT:\n",
        "    # range_fft_mag = np.abs(data_matrix)\n",
        "    # Compute full FFT for all chirps\n",
        "    range_fft_magnitude = compute_full_fft(data_matrix)\n",
        "    range_fft_data = np.fft.fft(data_matrix.T, axis=1)\n",
        "    # Step 2a: Find P_max for each chirp\n",
        "    for i in range(num_chirps):\n",
        "        P_max_value = np.max(range_fft_magnitude[i, :])  # Maximum value in the FFT magnitude\n",
        "        P_max.append(P_max_value)\n",
        "\n",
        "    # Step 2b: Find most frequent index in P_max\n",
        "    idx_max = np.argmax(np.bincount(np.array(P_max, dtype=int)))  # Most frequent index\n",
        "\n",
        "\n",
        "    # 2) Find the bin with max average magnitude\n",
        "    # avg_mag_bins = np.mean(range_fft_mag, axis=0)  # shape: (num_range_bins,)\n",
        "    # idx_max = np.argmax(avg_mag_bins)\n",
        "    # print(\"idx_max:\", idx_max)\n",
        "\n",
        "    # 3) Pick a small interval around idx_max\n",
        "    #    e.g., if r_values = [1], we do ±1 bin around idx_max\n",
        "    #    Or we just pick r_values[0].\n",
        "    half_width = r_values[0]\n",
        "    start = max(0, idx_max - half_width)\n",
        "    # end   = min(num_samples, idx_max + half_width + 1)\n",
        "    end   = min(num_samples, idx_max + half_width)\n",
        "\n",
        "    # print(start)\n",
        "    # print(end)\n",
        "    # 4) Accumulate STFT magnitudes across these bins\n",
        "    accum = None\n",
        "    count = 0\n",
        "\n",
        "    nperseg = 128\n",
        "    noverlap = 64\n",
        "\n",
        "    for rb in range(start, end):\n",
        "        slow_time_signal = range_fft_data[:, rb].copy()\n",
        "\n",
        "        # Ensure nperseg <= length of slow_time_signal\n",
        "        nperseg_local = min(nperseg, len(slow_time_signal))\n",
        "        noverlap_local = min(noverlap, nperseg_local - 1)\n",
        "\n",
        "        # Compute full STFT\n",
        "        f, t, Zxx = stft(\n",
        "            slow_time_signal,\n",
        "            fs=fs_slow,\n",
        "            nperseg=nperseg_local,\n",
        "            noverlap=noverlap_local,\n",
        "            window='hann',\n",
        "            return_onesided=False\n",
        "        )\n",
        "\n",
        "        # Center the Doppler axis\n",
        "        Zxx_shifted = np.fft.fftshift(Zxx, axes=0)\n",
        "        f_shifted = np.fft.fftshift(f)\n",
        "\n",
        "        # Accumulate magnitudes\n",
        "        mag = np.abs(Zxx_shifted)\n",
        "        if accum is None:\n",
        "            accum = mag\n",
        "        else:\n",
        "            accum += mag\n",
        "        count += 1\n",
        "\n",
        "    # Average across selected bins\n",
        "    avg_mag = accum / max(count, 1)\n",
        "\n",
        "    # Convert to dB => see both signal and noise\n",
        "    spec_db = 20.0 * np.log10(avg_mag + 1e-12)\n",
        "    return f_shifted, t, spec_db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "GE0fJ4vNcGzo",
        "outputId": "fc4861c3-f620-48a1-f725-9bcf9dd7b017"
      },
      "outputs": [],
      "source": [
        "f_centered, t, spec_db_centered =  compute_spectrogram(data_matrix,r_values,fs_slow=1000.0)\n",
        "\n",
        "plot_original_spectrogram(\n",
        "    f_centered, t, spec_db_centered,\n",
        "    title=\"Original Micro-Doppler Spectrogram\",\n",
        "    time_lims=(0, 8),\n",
        "    caxis=(-60, -20)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au75rQd5cpek"
      },
      "source": [
        "## Generate Noisy Spectrograms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zZ_ewvtusI-f",
        "outputId": "aa2a172a-f8b7-47f4-9bd2-38872ef19240"
      },
      "outputs": [],
      "source": [
        "generate_noisy_spectrograms(data_matrix, snr_list, fs_slow=1000.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yosnzKAt9Rk",
        "outputId": "ceef9b10-3748-4a14-96db-ab7c0e246b3f"
      },
      "outputs": [],
      "source": [
        "noisy_data_dict = {}\n",
        "snr_levels = [-15, -5, 0, 5, 10]\n",
        "for snr in snr_levels:\n",
        "        noisy_data = add_awgn(data_matrix, snr)\n",
        "        noisy_data_dict[snr] = noisy_data\n",
        "        # Optionally, save to file:\n",
        "        # filename = f\"data_noise_{snr}dB.npy\"\n",
        "        # np.save(filename, noisy_data)\n",
        "        # print(f\"Saved noisy data at {snr} dB to {filename}\")\n",
        "\n",
        "# Now you have variables like:\n",
        "data_noise_minus15_dB = noisy_data_dict[-15]\n",
        "data_noise_minus5_dB  = noisy_data_dict[-5]\n",
        "data_noise_0_dB       = noisy_data_dict[0]\n",
        "data_noise_5_dB       = noisy_data_dict[5]\n",
        "data_noise_10_dB      = noisy_data_dict[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PVhEwzQWGKQP",
        "outputId": "809c7f1c-dabe-44af-f962-5641ed451ab6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "\n",
        "\"\"\"\n",
        "Entropy-based denoising algorithm.\n",
        "Few changes from Munia's code\n",
        "- We use 50% overlap instead of 90%\n",
        "- We use Hann window instead of G window\n",
        "\"\"\"\n",
        "def algo_EBD(signal_data, optimal_range, Th=3, fs_slow=1000.0):\n",
        "    \"\"\"\n",
        "    Entropy-based denoising algorithm: Denoise using adaptive STFT thresholding.\n",
        "    Instead of plotting directly, returns the thresholded STFT in complex form,\n",
        "    plus frequency/time arrays so you can plot a spectrogram that matches your\n",
        "    'raw/noisy' style.\n",
        "\n",
        "    Parameters:\n",
        "      signal_data: shape (num_chirps, num_samples)\n",
        "      optimal_range: (start, end) for the selected range bins\n",
        "      Th: threshold factor\n",
        "      fs_slow: slow-time sampling rate (1000 Hz since 1 ms per chirp)\n",
        "\n",
        "    Returns:\n",
        "      denoised_stft_accum: complex 2D array (freq_bins x time_frames),\n",
        "                           after thresholding & averaging across the selected bins\n",
        "      f: frequency bins (in Hz)\n",
        "      t: time bins (in s)\n",
        "    \"\"\"\n",
        "    num_chirps, num_samples = signal_data.shape\n",
        "    # print(f\"Before input function: {np.shape(signal_data)}\")\n",
        "    # 1) Range FFT (fast-time)\n",
        "    range_fft = np.fft.fft(signal_data.T, axis=1)  # shape: (num_chirps, num_samples)\n",
        "\n",
        "    start, end = optimal_range\n",
        "    selected_bins = range(start, end)\n",
        "\n",
        "    denoised_stft_accum = None\n",
        "    count_bins = 0\n",
        "\n",
        "    # For each selected range bin, do STFT of slow-time signal & threshold\n",
        "    for rb in selected_bins:\n",
        "        slow_time_signal = range_fft[:, rb]\n",
        "\n",
        "        nperseg = min(128, len(slow_time_signal))\n",
        "        # noverlap = int(0.9 * nperseg)\n",
        "        noverlap = int(0.5 * nperseg)\n",
        "        f, t, Zxx = signal.stft(\n",
        "            slow_time_signal,\n",
        "            fs=fs_slow,\n",
        "            nperseg=nperseg,\n",
        "            noverlap=noverlap,\n",
        "            # window=('gaussian', 14),\n",
        "            window='hann',\n",
        "            return_onesided=False\n",
        "        )\n",
        "\n",
        "        # Adaptive thresholding for each time frame\n",
        "        Zxx_denoised = np.zeros_like(Zxx, dtype=complex)\n",
        "        for i in range(Zxx.shape[1]):\n",
        "            frame = Zxx[:, i].copy()\n",
        "            mag = np.abs(frame)\n",
        "            avg_mag = np.mean(mag)\n",
        "            threshold = Th * avg_mag\n",
        "            mask = (mag > threshold)\n",
        "            frame[~mask] = 0\n",
        "            Zxx_denoised[:, i] = frame\n",
        "\n",
        "        if denoised_stft_accum is None:\n",
        "            denoised_stft_accum = np.zeros_like(Zxx_denoised, dtype=complex)\n",
        "        denoised_stft_accum += Zxx_denoised\n",
        "        count_bins += 1\n",
        "\n",
        "    if count_bins > 0:\n",
        "        denoised_stft_accum /= count_bins\n",
        "    else:\n",
        "        print(\"Warning: No bins were selected. Returning None.\")\n",
        "        return None, None, None\n",
        "\n",
        "    # print(f\"After function {np.shape(denoised_stft_accum)}\")\n",
        "\n",
        "    return denoised_stft_accum, f, t\n",
        "\n",
        "def plot_denoised_spectrogram(denoised_stft_accum, f, t, title=\"Denoised Micro-Doppler Spectrogram\",caxis=None):\n",
        "    \"\"\"\n",
        "    Plot the denoised STFT in the same style as your raw/noisy spectrogram.\n",
        "    \"\"\"\n",
        "    denoised_mag = np.abs(denoised_stft_accum)\n",
        "    # range_fft_data = np.fft.fft(denoised_stft_accum.T, axis=1)\n",
        "\n",
        "    # f, t, Zxx = stft(\n",
        "    #     slow_time_signal,\n",
        "    #     fs=fs_slow,\n",
        "    #     nperseg=nperseg_local,\n",
        "    #     noverlap=noverlap_local,\n",
        "    #     window='hann',\n",
        "    #     return_onesided=False\n",
        "    # )\n",
        "\n",
        "    # denoised_db = 20.0 * np.log10(np.abs(range_fft_data) + 1e-12)\n",
        "    denoised_db = 20.0 * np.log10(denoised_mag + 1e-12)\n",
        "\n",
        "    # fftshift along freq axis\n",
        "    denoised_db_shifted = np.fft.fftshift(denoised_db, axes=0)\n",
        "    f_shifted = np.fft.fftshift(f)\n",
        "\n",
        "    # Plot\n",
        "    # plt.figure(figsize=(10,5))\n",
        "    plt.figure(figsize=(8,6))\n",
        "    extent = [t[0], t[-1], f_shifted[0], f_shifted[-1]]\n",
        "    plt.imshow(denoised_db_shifted, origin='lower', aspect='auto',\n",
        "               extent=extent, cmap='jet')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Doppler Frequency (Hz)\")\n",
        "    plt.colorbar(label=\"Magnitude (dB)\")\n",
        "    if caxis is not None:\n",
        "        plt.clim(caxis[0], caxis[1])\n",
        "    # plt.ylim([-400, 400]) # if you want to zoom\n",
        "    plt.xlim([0, 8])      # if you have 8 s\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# data_noise_ = noisy_data_dict[-15]\n",
        "data_noise_ = data_noise_minus15_dB\n",
        "f_noisy, t_noisy, spec_db_noisy=  compute_spectrogram(data_noise_, r_values=[1], fs_slow=fs_slow)\n",
        "\n",
        "# Plot and save the noisy spectrogram image\n",
        "plt.figure(figsize=(8,6))\n",
        "extent = [t_noisy.min(), t_noisy.max(), f_noisy[0], f_noisy[-1]]\n",
        "plt.imshow(spec_db_noisy, origin='lower', aspect='auto', extent=extent, cmap='jet')\n",
        "plt.title(\"Noisy Micro-Doppler Spectrogram (SNR=-15 dB)\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Doppler Frequency (Hz)\")\n",
        "plt.colorbar(label=\"Magnitude (dB)\")\n",
        "plt.clim(-60, -20)\n",
        "plt.xlim([0, 8])\n",
        "plt.tight_layout()\n",
        "# plt.savefig(f\"data_noise_minus15_dB.png\", dpi=150)\n",
        "plt.show()\n",
        "# print(\"Noisy spectrogram image saved as 'noisy_spectrogram.png'.\")\n",
        "\n",
        "# Call EBD algorithm here\n",
        "optimal_range = get_optimal_range_bin(data_noise_, r_values)\n",
        "# print(optimal_range)\n",
        "Th = 3  # Threshold value determined empirically.\n",
        "denoised_stft, f_den, t_den = algo_EBD(data_noise_, optimal_range, Th=3, fs_slow=1000.0)\n",
        "\n",
        "plot_denoised_spectrogram(denoised_stft, f_den, t_den, title=\"Denoised Micro-Doppler Spectrogram\",caxis=(-60, -20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2FL5ObnGKL_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_global_threshold_db(spec_db, V=0.1):\n",
        "    \"\"\"\n",
        "    Iteratively find a global threshold T in a 2D array of dB values (spec_db).\n",
        "    Flatten the array, repeatedly split around 'mu' until difference < V.\n",
        "    Returns T in dB (float).\n",
        "    \"\"\"\n",
        "    flattened = spec_db.flatten().astype(np.float32)\n",
        "    mu = np.mean(flattened)\n",
        "    diff = V + 1\n",
        "    T = 0\n",
        "    while diff > V:\n",
        "        if T != 0:\n",
        "            mu = T\n",
        "        group1 = flattened[flattened > mu]\n",
        "        group2 = flattened[flattened <= mu]\n",
        "        if group1.size == 0 or group2.size == 0:\n",
        "            break\n",
        "        T_new = 0.5 * (np.mean(group1) + np.mean(group2))\n",
        "        diff = abs(T_new - mu)\n",
        "        T = T_new\n",
        "    # print(f\"[Algo3] Final global threshold T in dB = {T:.2f}\")\n",
        "    return T\n",
        "\n",
        "def algo_ADTh(spec_db, vmin=-60, vmax=-20, tol=0.1, plot=False):\n",
        "    \"\"\"\n",
        "    spec_db: 2D array (freq_bins x time_bins) in dB\n",
        "    vmin, vmax: color scale range\n",
        "    tol: iteration tolerance for get_global_threshold_db\n",
        "\n",
        "    1) Find threshold T from spec_db\n",
        "    2) For all pixels < T, set them to vmin (e.g., -60 dB).\n",
        "    3) Optionally plot the denoised spectrogram.\n",
        "    4) Return the denoised 2D array (same shape as spec_db).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Find threshold T\n",
        "    T = get_global_threshold_db(spec_db, V=tol)\n",
        "\n",
        "    # 2) Clamp values below T\n",
        "    denoised_data = spec_db.copy()\n",
        "    denoised_data[denoised_data < T] = vmin\n",
        "\n",
        "    # 3) Optionally plot\n",
        "    if plot:\n",
        "        fig, ax = plt.subplots(figsize=(8,6))\n",
        "        im = ax.imshow(denoised_data, origin='lower', aspect='auto',\n",
        "                       cmap='jet', vmin=vmin, vmax=vmax)\n",
        "        ax.set_title(\"Denoised Micro-Doppler (Algorithm 3: Global Threshold)\")\n",
        "        ax.set_xlabel(\"Time (s)\")\n",
        "        ax.set_ylabel(\"Doppler Frequency (Hz)\")\n",
        "        cbar = fig.colorbar(im, ax=ax, label=\"Magnitude (dB)\")\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # 4) Return denoised array\n",
        "    return denoised_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ok_-OdTWGKOH",
        "outputId": "29aebf45-2bcb-4752-b1f2-0872a7ddc56c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from scipy import signal\n",
        "from scipy.stats import pearsonr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def compute_global_metrics(ref, test, data_is_db=True):\n",
        "    \"\"\"\n",
        "    Compute common image-quality metrics between reference and test images (2D arrays).\n",
        "    Assumes both are in the same scale (dB or linear).\n",
        "\n",
        "    Args:\n",
        "        ref (2D np.array): Reference spectrogram (noise-free).\n",
        "        test (2D np.array): Test spectrogram (noisy or denoised).\n",
        "        data_is_db (bool): If True, interpret the arrays as dB images. This affects PSNR calculation.\n",
        "\n",
        "    Returns:\n",
        "        metrics (dict): Dictionary containing MSE, MAE, PSNR, Correlation, SSIM.\n",
        "    \"\"\"\n",
        "    # Ensure shapes match\n",
        "    if ref.shape != test.shape:\n",
        "        raise ValueError(f\"Shapes differ! ref={ref.shape}, test={test.shape}\")\n",
        "\n",
        "    # Flatten for some metrics\n",
        "    ref_flat = ref.flatten()\n",
        "    test_flat = test.flatten()\n",
        "\n",
        "    # 1) MSE\n",
        "    mse_val = np.mean((ref_flat - test_flat) ** 2)\n",
        "\n",
        "    # 2) MAE\n",
        "    mae_val = np.mean(np.abs(ref_flat - test_flat))\n",
        "\n",
        "    rmse_val = np.sqrt(mse_val)\n",
        "\n",
        "    # 3) PSNR\n",
        "    #   In dB images, you can either:\n",
        "    #     (A) Use max of reference in dB, or\n",
        "    #     (B) Convert from dB -> linear, then compute PSNR in linear scale.\n",
        "    #   Here, we do a \"dB-domain\" style PSNR using the max ref value in dB:\n",
        "    ref_max = np.max(ref)\n",
        "    if mse_val == 0:\n",
        "        psnr_val = np.inf\n",
        "    else:\n",
        "        psnr_val = 10.0 * np.log10((ref_max**2) / mse_val)\n",
        "\n",
        "    # 4) Correlation Coefficient\n",
        "    corr_val, _ = pearsonr(ref_flat, test_flat)\n",
        "\n",
        "    # 5) SSIM\n",
        "    #   SSIM in skimage requires specifying data_range = max - min for correct results.\n",
        "    #   If your data is in dB, data_range is (max_dB - min_dB).\n",
        "    data_range = ref_max - np.min(ref)\n",
        "    ssim_val = ssim(ref, test, data_range=data_range)\n",
        "\n",
        "    metrics = {\n",
        "        'MSE': mse_val,\n",
        "        'MAE': mae_val,\n",
        "        'RMSE': rmse_val,\n",
        "        'PSNR': psnr_val,\n",
        "        'Correlation': corr_val,\n",
        "        'SSIM': ssim_val\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "from scipy.interpolate import RegularGridInterpolator\n",
        "\n",
        "def unify_spectrograms(spec1, spec2, T_common=200, F_common=256):\n",
        "    \"\"\"\n",
        "    Interpolate two spectrograms to the same shape (T_common x F_common).\n",
        "    Returns (spec1_unified, spec2_unified).\n",
        "    \"\"\"\n",
        "    t1_size, f1_size = spec1.shape\n",
        "    t2_size, f2_size = spec2.shape\n",
        "\n",
        "    # Original coordinate grids\n",
        "    t1 = np.linspace(0, 1, t1_size)\n",
        "    f1 = np.linspace(0, 1, f1_size)\n",
        "    t2 = np.linspace(0, 1, t2_size)\n",
        "    f2 = np.linspace(0, 1, f2_size)\n",
        "\n",
        "    # Interpolating to new grid\n",
        "    new_t = np.linspace(0, 1, T_common)\n",
        "    new_f = np.linspace(0, 1, F_common)\n",
        "    TT, FF = np.meshgrid(new_t, new_f, indexing='ij')  # shape (T_common, F_common)\n",
        "\n",
        "    interp1 = RegularGridInterpolator((t1, f1), spec1)\n",
        "    interp2 = RegularGridInterpolator((t2, f2), spec2)\n",
        "\n",
        "    points = np.stack([TT.ravel(), FF.ravel()], axis=-1)\n",
        "    spec1_unif = interp1(points).reshape(T_common, F_common)\n",
        "    spec2_unif = interp2(points).reshape(T_common, F_common)\n",
        "\n",
        "    return spec1_unif, spec2_unif\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def main():\n",
        "    # List of spectrogram data sets to test, only the ones in this list will be tested\n",
        "    # STW dataset seems to have some corrupt data, so it is excluded\n",
        "    spectrogram_types = [\"B\", \"FTW\", \"G\", \"K\", \"P\", \"SD\", \"SU\", \"W\", \"WTF\", \"WTS\"]\n",
        "\n",
        "\n",
        "    try:\n",
        "        os.mkdir('./noisy_data')\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "\n",
        "    for spec_type in spectrogram_types:\n",
        "        try:\n",
        "            os.mkdir(f'./noisy_data/{spec_type}')\n",
        "        except FileExistsError:\n",
        "            pass\n",
        "\n",
        "    for spec_type in spectrogram_types:\n",
        "        ebd_time_sum = 0\n",
        "        adth_time_sum = 0\n",
        "        sample_count = 0\n",
        "        ebd_time_list = []\n",
        "        adth_time_list = []\n",
        "\n",
        "        _, _, files = next(os.walk(os.getcwd() + f'/clean_data/{spec_type}/'))\n",
        "        file_count = len(files)\n",
        "\n",
        "        for i in range(1, file_count + 1):\n",
        "            # 1) Load your data\n",
        "            file_path = os.getcwd() + f'/clean_data/{spec_type}/3m_0_file{i}.mat'\n",
        "            print (f\"Now executing algos on {spec_type} spectrogram file {f'/clean_data/{spec_type}/3m_0_file{i}.mat'}\")\n",
        "            data_matrix = load_radar_data(file_path)  # shape: (num_chirps, num_samples)\n",
        "            r_values=[1]\n",
        "\n",
        "            snr_list = [-15, -5, 0, 5, 10]\n",
        "            for snr in snr_list:\n",
        "                res = single_itr(file_path, data_matrix, i, snr, spec_type)\n",
        "                ebd_time_sum += res[0]\n",
        "                adth_time_sum += res[1]\n",
        "                ebd_time_list.append(res[0])\n",
        "                adth_time_list.append(res[1])\n",
        "                sample_count += 1\n",
        "\n",
        "        print(f\"\\nSummary for [{spec_type}]:\")\n",
        "        print(f\"EBD Time List for [{spec_type}]:\")\n",
        "        print(ebd_time_list)\n",
        "        print(\"\")\n",
        "        print(f\"AdTh Time List for [{spec_type}]:\")\n",
        "        print(adth_time_list)\n",
        "        print(\"\")\n",
        "        print(f\"Average EBD time for [{spec_type}] ({sample_count} samples): {ebd_time_sum/60} s\")\n",
        "        print(f\"Average AdTh time for [{spec_type}] ({sample_count} samples): {adth_time_sum/60} s\\n\")   \n",
        "\n",
        "\n",
        "def single_itr(file_path, data_matrix, file_num, snr, spec_type): \n",
        "    EBD_REPS = 2\n",
        "    ADTH_REPS = 100\n",
        "\n",
        "    # 2) Compute ORIGINAL spectrogram in dB\n",
        "    f_orig, t_orig, spec_db_original = compute_spectrogram(\n",
        "        data_matrix, r_values=[1], fs_slow=1000.0\n",
        "    )\n",
        "    # spec_db_original is your \"noise-free\" reference\n",
        "\n",
        "    # 3) Add noise here if noisy spectrogram does not exist\n",
        "\n",
        "    # for snr in snr_list:\n",
        "    filename = f\"./noisy_data/{spec_type}/data_noisy{file_num}_{snr}dB.npy\"\n",
        "    if os.path.isfile(filename) == False:\n",
        "        data_noisy_ = add_awgn(data_matrix, snr_db=snr)\n",
        "        np.save(filename, data_noisy_)\n",
        "\n",
        "    # Load from .npy noisy data to keep it consistent\n",
        "    data_noisy_ = np.load(filename)\n",
        "\n",
        "    # 4) Compute noisy spectrogram in dB\n",
        "    f_noisy, t_noisy, spec_db_noisy = compute_spectrogram(\n",
        "        data_noisy_, r_values=[1], fs_slow=1000.0\n",
        "    )\n",
        "\n",
        "    # 5) Denoise\n",
        "\n",
        "    # Start timer for EBD algo\n",
        "    st1 = time.process_time()\n",
        "\n",
        "    # Repeat x times and take the average\n",
        "    for k in range (EBD_REPS):\n",
        "        optimal_range = get_optimal_range_bin(data_noisy_, r_values)\n",
        "        # print(optimal_range)\n",
        "        Th = 3  # Threshold value determined empirically.\n",
        "        denoised_stft_algo_EBD, f_den, t_den = algo_EBD(data_noisy_, optimal_range, Th=3, fs_slow=1000.0)\n",
        "\n",
        "        # Convert the complex STFT output to dB\n",
        "        denoised_stft_algo_EBD_mag = np.abs(denoised_stft_algo_EBD)\n",
        "        spec_db_denoised = 20.0 * np.log10(denoised_stft_algo_EBD_mag + 1e-12)\n",
        "        # # Then apply fftshift along freq axis to match your \"centered\" style\n",
        "        spec_db_denoised_algo_EBD = np.fft.fftshift(spec_db_denoised, axes=0)\n",
        "\n",
        "    # End timer for EBD algo\n",
        "    et1 = time.process_time()\n",
        "\n",
        "    # Start timer for ADTh algo\n",
        "    st2 = time.process_time()\n",
        "\n",
        "    # Repeat x times and take the average\n",
        "    for k in range (ADTH_REPS):\n",
        "        spec_db_denoised_algo_ADTh = algo_ADTh(\n",
        "            spec_db_noisy, vmin=-60, vmax=-20, tol=0.1, plot=False\n",
        "        )\n",
        "\n",
        "    # End timer for ADTh algo\n",
        "    et2 = time.process_time()\n",
        "\n",
        "    # 6) If needed, unify shapes (only if your original/noisy/denoised have different shapes)\n",
        "    # print(f\"spec_db_original: {spec_db_original.shape}\")\n",
        "    # print(f\"spec_db_noisy.shape: {spec_db_noisy.shape}\")\n",
        "    # print(f\"spec_db_denoised_algo_EBD.shape: {spec_db_denoised_algo_EBD.shape}\")\n",
        "    # print(f\"spec_db_denoised_algo_ADTh.shape:     {spec_db_denoised_algo_ADTh.shape}\")\n",
        "\n",
        "    if spec_db_original.shape != spec_db_noisy.shape:\n",
        "        spec_db_original_unif, spec_db_noisy_unif = unify_spectrograms(\n",
        "            spec_db_original, spec_db_noisy,\n",
        "            T_common=200, F_common=256\n",
        "        )\n",
        "    else:\n",
        "        spec_db_original_unif = spec_db_original\n",
        "        spec_db_noisy_unif = spec_db_noisy\n",
        "\n",
        "    # If original != algo_EBD, unify them\n",
        "    if spec_db_original_unif.shape != spec_db_denoised_algo_EBD.shape:\n",
        "        spec_db_original_unif, spec_db_denoised_algo_EBD_unif = unify_spectrograms(\n",
        "            spec_db_original_unif, spec_db_denoised_algo_EBD,\n",
        "            T_common=200, F_common=256\n",
        "        )\n",
        "    else:\n",
        "        spec_db_denoised_algo_EBD_unif = spec_db_denoised_algo_EBD\n",
        "\n",
        "    # If original != algo_ADTh, unify them\n",
        "    if spec_db_original_unif.shape != spec_db_denoised_algo_ADTh.shape:\n",
        "        spec_db_original_unif, sspec_db_denoised_algo_ADTh_unif = unify_spectrograms(\n",
        "            spec_db_original_unif, spec_db_denoised,\n",
        "            T_common=200, F_common=256\n",
        "        )\n",
        "    else:\n",
        "        sspec_db_denoised_algo_ADTh_unif = spec_db_denoised_algo_ADTh\n",
        "\n",
        "    # 7) Compute metrics: (noisy vs. original) and (denoised vs. original)\n",
        "    noisy_metrics = compute_global_metrics(spec_db_original_unif, spec_db_noisy_unif)\n",
        "    denoised_EBD_metrics = compute_global_metrics(spec_db_original_unif, spec_db_denoised_algo_EBD_unif)\n",
        "    denoised_ADTh_metrics = compute_global_metrics(spec_db_original_unif, sspec_db_denoised_algo_ADTh_unif)\n",
        "\n",
        "    # 8) Print results\n",
        "    if True:\n",
        "        print(f\"=== Evaluation Results for spectrogram {spec_type}{file_num} with {snr}dB SNR ===\")\n",
        "        print('EBD algo CPU Execution time:', (et1 - st1)/EBD_REPS, 'seconds')\n",
        "        print('ADTh algo CPU Execution time:', (et2 - st2)/ADTH_REPS, 'seconds')\n",
        "        print(\"[Noisy vs. Original:]\")\n",
        "        for k, v in noisy_metrics.items():\n",
        "            print(f\"  {k}: {v:.4f}\")\n",
        "        print(\"[Denoised EBD vs. Original]\")\n",
        "        for k, v in denoised_EBD_metrics.items():\n",
        "            print(f\"  {k}: {v:.4f}\")\n",
        "        print(\"[Denoised ADTh vs. Original]\")\n",
        "        for k, v in denoised_ADTh_metrics.items():\n",
        "            print(f\"  {k}: {v:.4f}\")\n",
        "        print(\"\")\n",
        "\n",
        "    # 9) (Optional) Plot side-by-side for visual inspection\n",
        "\n",
        "    if False:\n",
        "        plt.figure(figsize=(12,8))\n",
        "        plt.subplot(2,2,1)\n",
        "        plt.title(f\"Original Spectrogram [{spec_type}{file_num}] (dB)\")\n",
        "        plt.imshow(spec_db_original_unif, aspect='auto', cmap='jet')\n",
        "        plt.clim(-60, -20)  # or adjust\n",
        "        plt.colorbar()\n",
        "\n",
        "        plt.subplot(2,2,2)\n",
        "        plt.title(f\"White Gaussian Noise Spectrogram (SNR = {snr} dB)\")\n",
        "        plt.imshow(spec_db_noisy_unif, aspect='auto', cmap='jet')\n",
        "        plt.clim(-60, -20)  # or adjust\n",
        "        plt.colorbar()\n",
        "\n",
        "        plt.subplot(2,2,3)\n",
        "        plt.title(\"Entropy-Based Denoising\")\n",
        "        plt.imshow(spec_db_denoised_algo_EBD_unif, aspect='auto', cmap='jet')\n",
        "        plt.clim(-60, -20)  # or adjust\n",
        "        plt.colorbar()\n",
        "\n",
        "        plt.subplot(2,2,4)\n",
        "        plt.title(\"Adaptive Thresholding Denoising\")\n",
        "        plt.imshow(sspec_db_denoised_algo_ADTh_unif, aspect='auto', cmap='jet', vmin=-60, vmax=-20)\n",
        "        plt.colorbar()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # print(f\"Done processing spectrogram {spec_type}{file_num} with {snr}dB SNR\")\n",
        "\n",
        "    return ((et1 - st1)/EBD_REPS, (et2 - st2)/ADTH_REPS)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
